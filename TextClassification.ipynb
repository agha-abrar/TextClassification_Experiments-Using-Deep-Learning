{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJWL8cvmbIL_",
        "outputId": "7704fe8b-66f7-4110-cba5-944834566a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Datasets/ecommerceDataset.csv', header=None, names=['Class', 'Text'])\n",
        "\n",
        "class_counts = data['Class'].value_counts()\n",
        "print(\"Class counts:\\n\", class_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB6fEqZybPcp",
        "outputId": "90410336-be38-460c-f359-79cb7692a2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts:\n",
            " Class\n",
            "Household                 19313\n",
            "Books                     11820\n",
            "Electronics               10621\n",
            "Clothing & Accessories     8671\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Riz3gJ8zb6wj",
        "outputId": "e1dd37e2-9db3-4ca7-e659-14c8c4d826ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Class                                               Text\n",
              "0  Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
              "1  Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
              "2  Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
              "3  Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
              "4  Household  Incredible Gifts India Wooden Happy Birthday U..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29e7cc06-a203-4e19-b0b8-d3f56cf9b96c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Household</td>\n",
              "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Household</td>\n",
              "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Household</td>\n",
              "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Household</td>\n",
              "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Household</td>\n",
              "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29e7cc06-a203-4e19-b0b8-d3f56cf9b96c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29e7cc06-a203-4e19-b0b8-d3f56cf9b96c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29e7cc06-a203-4e19-b0b8-d3f56cf9b96c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ba55d8a4-4dff-4350-88ff-608796fb5583\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba55d8a4-4dff-4350-88ff-608796fb5583')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ba55d8a4-4dff-4350-88ff-608796fb5583 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 50425,\n  \"fields\": [\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Books\",\n          \"Electronics\",\n          \"Household\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27802,\n        \"samples\": [\n          \"Canon EOS 1500D Digital SLR Camera (Black) with EF S18-55 is II Lens/Camera Case Style name:EF S18-55   All camera users, even beginners, will be able to capture amazing images and movies with this DSLR camera, which is equipped with a 24.1-megapixel APS-C-size CMOS sensor and an optical viewfinder for an authentic DSLR shooting experience. Capturing sharp images is easy thanks to the fast, accurate AF and the large grip that provides a firm, steady hold on the camera. Built-in Wi-Fi / NFC connectivity enables the seamless upload of photos and videos to social media.\",\n          \"NIRVA Electric Automatic Yogurt Maker 1L Electronic Stainless Steel Mini Portable Yogurt Making Machine Yogurt Maker (Pink) Color Name:Pink   Add natural yogurt or culture to pre-boiled milk then get creative with flavors and ingredients. Fill yogurt with your favorite fruit or go for something a little naughtier such as chocolate chips \\u2013 the options are endless! to make yogurts just how you like them. Yogurt Maker automatically cools and ferments ingredients to create 100% natural healthy yogurt with no coloring's, preservatives or artificial flavors. Specification: Material: Plastic, 304 Stainless Steel Voltage: 220V/50Hz(please note if it fits your country standard) Power: 15W Frequency: 50Hz Capacity: 1L(approx) Feature: Make fresh and healthy yogurt in your own home quickly and easily, with the flip of a switch. 360\\u00b0stereo fermentation guarantee the taste of yogurt smooth and fine, mellow and fresh. Made from food grade quality materials, safe and harmless, way to use and eat yogurt. Auto control. You can just put the material inside, close the lid and power on to make the machine work. You can just put the material inside, close the lid and power on to make the machine work. Wih the help of it, you can make fresh yogurt at home by yourself quickly and easily.How To Use Step 1) Pour Fresh Milk into the stainless steel Container, Step 2) Add 2-3 table spoon of fresh plain Yogurt or 1 gram of yeast, Step 3) Switch on the maker and leave it for 8-9 hours, Step 4) After 8-9 hours, Your Yogurt is ready\",\n          \"SHOPTOSHOP Plastic Lint Cum Fuzz Remover for All Woolenss (Multicolour) Lint remover,remove the fuzz instantly without damaging clothes. It is made of plastic.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.lower()\n",
        "\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "\n",
        "data['Text'] = data['Text'].apply(clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcQLT67ycRSD",
        "outputId": "721c3ff1-1b62-4e97-d749-cd9e8257dff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_data, test_data = train_test_split(\n",
        "    data, test_size=0.3, stratify=data['Class'], random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "train_texts = train_data['Text'].values\n",
        "train_labels = train_data['Class'].values\n",
        "test_texts = test_data['Text'].values\n",
        "test_labels = test_data['Class'].values\n"
      ],
      "metadata": {
        "id": "rAeT6FgycWxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "train_labels = encoder.fit_transform(train_labels)\n",
        "test_labels = encoder.transform(test_labels)\n",
        "\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n"
      ],
      "metadata": {
        "id": "T2rnU6RYcaXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryiYI9oBccqH",
        "outputId": "592e61be-0fd8-499e-8d91-eff9a64eb311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. using TextVectorization with one-gram multi_hot encoding, keeping max feature size = 10000\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=10000, output_mode='multi_hot', ngrams=1)\n",
        "vectorizer.adapt(train_texts)\n",
        "\n",
        "model = Sequential([\n",
        "    vectorizer,\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(train_texts, train_labels, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdtmLnJVcfwn",
        "outputId": "0eafd5fd-03c8-405f-ff6b-0ebb713818c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.8639 - loss: 0.4450 - val_accuracy: 0.9620 - val_loss: 0.1568\n",
            "Epoch 2/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 47ms/step - accuracy: 0.9826 - loss: 21469798483361792.0000 - val_accuracy: 0.9640 - val_loss: 0.1513\n",
            "Epoch 3/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 46ms/step - accuracy: 0.9943 - loss: 0.0246 - val_accuracy: 0.9669 - val_loss: 0.1830\n",
            "Epoch 4/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.9968 - loss: 0.0156 - val_accuracy: 0.9669 - val_loss: 0.1799\n",
            "Epoch 5/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.9972 - loss: 0.0107 - val_accuracy: 0.9691 - val_loss: 0.1963\n",
            "Epoch 6/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 46ms/step - accuracy: 0.9976 - loss: 0.0092 - val_accuracy: 0.9666 - val_loss: 0.2086\n",
            "Epoch 7/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 48ms/step - accuracy: 0.9983 - loss: 0.0074 - val_accuracy: 0.9666 - val_loss: 0.2419\n",
            "Epoch 8/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 51ms/step - accuracy: 0.9974 - loss: 0.0078 - val_accuracy: 0.9669 - val_loss: 0.2311\n",
            "Epoch 9/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 46ms/step - accuracy: 0.9985 - loss: 0.0058 - val_accuracy: 0.9677 - val_loss: 0.2562\n",
            "Epoch 10/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 47ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 0.9688 - val_loss: 0.2385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "val_predictions = model.predict(val_texts)\n",
        "\n",
        "val_predictions = val_predictions.argmax(axis=1)\n",
        "\n",
        "val_true_labels = val_labels.argmax(axis=1)\n",
        "\n",
        "\n",
        "report = classification_report(val_true_labels, val_predictions, target_names=['Class 1', 'Class 2', 'Class 3', 'Class 4'], output_dict=True)\n",
        "\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "\n",
        "print(report_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv5Qcwi1xc07",
        "outputId": "15156ff1-09f8-4376-be8d-d3446fdd315a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "              precision    recall  f1-score      support\n",
            "Class 1        0.568733  0.931567  0.706276   453.000000\n",
            "Class 2        0.000000  0.000000  0.000000   380.000000\n",
            "Class 3        0.652244  0.922902  0.764319   441.000000\n",
            "Class 4        0.851182  0.754624  0.800000   811.000000\n",
            "accuracy       0.691127  0.691127  0.691127     0.691127\n",
            "macro avg      0.518040  0.652273  0.567649  2085.000000\n",
            "weighted avg   0.592606  0.691127  0.626287  2085.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. using TextVectorization with two-gram multi_hot encoding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=10000, output_mode='multi_hot', ngrams=2)\n",
        "vectorizer.adapt(train_texts)\n",
        "\n",
        "model = Sequential([\n",
        "    vectorizer,\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_texts, train_labels, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kXMnevgclUm",
        "outputId": "53f2c493-2687-4996-8e83-8e4faf27810c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 88ms/step - accuracy: 0.8548 - loss: nan - val_accuracy: 0.2320 - val_loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 96ms/step - accuracy: 0.2351 - loss: nan - val_accuracy: 0.2320 - val_loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 94ms/step - accuracy: 0.2355 - loss: nan - val_accuracy: 0.2320 - val_loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 97ms/step - accuracy: 0.2343 - loss: nan - val_accuracy: 0.2320 - val_loss: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 95ms/step - accuracy: 0.2395 - loss: nan - val_accuracy: 0.2320 - val_loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 94ms/step - accuracy: 0.2351 - loss: nan - val_accuracy: 0.2320 - val_loss: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 94ms/step - accuracy: 0.2345 - loss: nan - val_accuracy: 0.2320 - val_loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 94ms/step - accuracy: 0.2388 - loss: nan - val_accuracy: 0.2320 - val_loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 99ms/step - accuracy: 0.2326 - loss: nan - val_accuracy: 0.2320 - val_loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 95ms/step - accuracy: 0.2371 - loss: nan - val_accuracy: 0.2320 - val_loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "val_predictions = model.predict(val_texts)\n",
        "\n",
        "\n",
        "val_predictions = val_predictions.argmax(axis=1)\n",
        "\n",
        "\n",
        "val_true_labels = val_labels.argmax(axis=1)\n",
        "\n",
        "report = classification_report(val_true_labels, val_predictions, target_names=['Class 1', 'Class 2', 'Class 3', 'Class 4'], output_dict=True)\n",
        "\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "print(report_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3rGBqlCxbIW",
        "outputId": "09c28a1a-76a5-4e20-ca50-002a822fd3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "              precision    recall  f1-score      support\n",
            "Class 1        0.607143  0.927948  0.734024   458.000000\n",
            "Class 2        0.000000  0.000000  0.000000   333.000000\n",
            "Class 3        0.660714  0.939086  0.775681   394.000000\n",
            "Class 4        0.842276  0.749638  0.793262   691.000000\n",
            "accuracy       0.699893  0.699893  0.699893     0.699893\n",
            "macro avg      0.527533  0.654168  0.575742  1876.000000\n",
            "weighted avg   0.597231  0.699893  0.634299  1876.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. using TextVectorization with two-gram tf_idf encoding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=10000, output_mode='tf_idf', ngrams=2)\n",
        "vectorizer.adapt(train_texts)\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    vectorizer,\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(train_texts, train_labels, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kLD_8dJgWdk",
        "outputId": "26b3df54-c360-4cf9-d40b-435e1944f0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 89ms/step - accuracy: 0.8622 - loss: 0.5376 - val_accuracy: 0.9598 - val_loss: 0.2051\n",
            "Epoch 2/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 85ms/step - accuracy: 0.9821 - loss: 0.0840 - val_accuracy: 0.9615 - val_loss: 0.1879\n",
            "Epoch 3/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.9908 - loss: 0.0411 - val_accuracy: 0.9654 - val_loss: 0.2213\n",
            "Epoch 4/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.9919 - loss: 0.0331 - val_accuracy: 0.9575 - val_loss: 0.2599\n",
            "Epoch 5/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 88ms/step - accuracy: 0.9916 - loss: 0.0391 - val_accuracy: 0.9657 - val_loss: 0.2466\n",
            "Epoch 6/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 84ms/step - accuracy: 0.9953 - loss: 0.0242 - val_accuracy: 0.9674 - val_loss: 0.2262\n",
            "Epoch 7/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 87ms/step - accuracy: 0.9966 - loss: 0.0136 - val_accuracy: 0.9694 - val_loss: 0.2673\n",
            "Epoch 8/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 87ms/step - accuracy: 0.9973 - loss: 0.0107 - val_accuracy: 0.9683 - val_loss: 0.2866\n",
            "Epoch 9/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 85ms/step - accuracy: 0.9963 - loss: 0.0169 - val_accuracy: 0.9671 - val_loss: 0.3508\n",
            "Epoch 10/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 85ms/step - accuracy: 0.9978 - loss: 0.0129 - val_accuracy: 0.9688 - val_loss: 0.3610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "val_predictions = model.predict(val_texts)\n",
        "\n",
        "val_predictions = val_predictions.argmax(axis=1)\n",
        "\n",
        "\n",
        "val_true_labels = val_labels.argmax(axis=1)\n",
        "\n",
        "\n",
        "report = classification_report(val_true_labels, val_predictions, target_names=['Class 1', 'Class 2', 'Class 3', 'Class 4'], output_dict=True)\n",
        "\n",
        "\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "\n",
        "print(report_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaPVVCK8xY_9",
        "outputId": "387ac35f-a96e-4061-f4e2-45c99684a047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "              precision    recall  f1-score      support\n",
            "Class 1        0.609635  0.926768  0.735471   396.000000\n",
            "Class 2        1.000000  0.003534  0.007042   283.000000\n",
            "Class 3        0.660886  0.947514  0.778661   362.000000\n",
            "Class 4        0.840989  0.735703  0.784831   647.000000\n",
            "accuracy       0.703199  0.703199  0.703199     0.703199\n",
            "macro avg      0.777878  0.653380  0.576501  1688.000000\n",
            "weighted avg   0.774749  0.703199  0.641529  1688.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define TextVectorization layer with max length 200, max tokens = 10000, and output mode = 'int'\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, TextVectorization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "vectorizer = TextVectorization(\n",
        "    max_tokens=10000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=200\n",
        ")\n",
        "\n",
        "vectorizer.adapt(train_texts)\n",
        "\n",
        "model = Sequential([\n",
        "    vectorizer,\n",
        "    Embedding(input_dim=10000, output_dim=32),\n",
        "    LSTM(32),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(train_texts, train_labels, epochs=5, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZIuLyg0g5MS",
        "outputId": "14ad579f-30a8-416a-baa0-906d914ea782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.3964 - loss: 1.3321 - val_accuracy: 0.4255 - val_loss: 1.2953\n",
            "Epoch 2/5\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.4871 - loss: 1.1798 - val_accuracy: 0.4159 - val_loss: 1.2925\n",
            "Epoch 3/5\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.4585 - loss: 1.2263 - val_accuracy: 0.6813 - val_loss: 0.8134\n",
            "Epoch 4/5\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7264 - loss: 0.6868 - val_accuracy: 0.7841 - val_loss: 0.5607\n",
            "Epoch 5/5\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8987 - loss: 0.3867 - val_accuracy: 0.9280 - val_loss: 0.3540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
        "val_predictions = model.predict(val_texts)\n",
        "\n",
        "val_predictions = val_predictions.argmax(axis=1)\n",
        "\n",
        "val_true_labels = val_labels.argmax(axis=1)\n",
        "report = classification_report(val_true_labels, val_predictions, target_names=['Class 1', 'Class 2', 'Class 3', 'Class 4'], output_dict=True)\n",
        "\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "\n",
        "print(report_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzWOPfhVxWBo",
        "outputId": "39fdd9dd-20ee-41da-e0d6-733650fb2932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "              precision    recall  f1-score      support\n",
            "Class 1        0.571942  0.893258  0.697368   356.000000\n",
            "Class 2        0.000000  0.000000  0.000000   259.000000\n",
            "Class 3        0.684564  0.932927  0.789677   328.000000\n",
            "Class 4        0.866538  0.776430  0.819013   577.000000\n",
            "accuracy       0.705263  0.705263  0.705263     0.705263\n",
            "macro avg      0.530761  0.650654  0.576515  1520.000000\n",
            "weighted avg   0.610619  0.705263  0.644637  1520.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. using GloVe\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, TextVectorization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "vectorizer = TextVectorization(\n",
        "    max_tokens=10000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=200\n",
        ")\n",
        "\n",
        "vectorizer.adapt(train_texts)\n",
        "\n",
        "def load_glove_embeddings(glove_file, embedding_dim=100):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "glove_file = '/content/drive/MyDrive/Datasets/glove.6B.100d.txt'\n",
        "embedding_dim = 100\n",
        "\n",
        "embeddings_index = load_glove_embeddings(glove_file, embedding_dim)\n",
        "\n",
        "embedding_matrix = np.zeros((10000, embedding_dim))\n",
        "for i in range(10000):\n",
        "    word = vectorizer.get_vocabulary()[i]\n",
        "    if word in embeddings_index:\n",
        "        embedding_matrix[i] = embeddings_index[word]\n",
        "\n",
        "model = Sequential([\n",
        "    vectorizer,\n",
        "    Embedding(input_dim=10000, output_dim=embedding_dim,\n",
        "              weights=[embedding_matrix], input_length=200, trainable=False),\n",
        "    LSTM(32),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_texts, train_labels, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ0lLuw0hPgE",
        "outputId": "f930a8ee-5243-41a8-bfb9-5b2ac3384d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.4820 - loss: 1.1885 - val_accuracy: 0.6779 - val_loss: 0.8387\n",
            "Epoch 2/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6939 - loss: 0.7941 - val_accuracy: 0.7255 - val_loss: 0.7341\n",
            "Epoch 3/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6313 - loss: 0.8809 - val_accuracy: 0.6941 - val_loss: 0.8218\n",
            "Epoch 4/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.7080 - loss: 0.7543 - val_accuracy: 0.7227 - val_loss: 0.7416\n",
            "Epoch 5/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6928 - loss: 0.7913 - val_accuracy: 0.6459 - val_loss: 0.9762\n",
            "Epoch 6/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.7155 - loss: 0.7900 - val_accuracy: 0.7742 - val_loss: 0.6185\n",
            "Epoch 7/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7704 - loss: 0.6178 - val_accuracy: 0.7340 - val_loss: 0.6314\n",
            "Epoch 8/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.7351 - loss: 0.6253 - val_accuracy: 0.7306 - val_loss: 0.6596\n",
            "Epoch 9/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7636 - loss: 0.6111 - val_accuracy: 0.7901 - val_loss: 0.6701\n",
            "Epoch 10/10\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.8230 - loss: 0.5671 - val_accuracy: 0.8212 - val_loss: 0.5643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
        "val_predictions = model.predict(val_texts)\n",
        "\n",
        "val_predictions = val_predictions.argmax(axis=1)\n",
        "\n",
        "val_true_labels = val_labels.argmax(axis=1)\n",
        "\n",
        "\n",
        "report = classification_report(val_true_labels, val_predictions, target_names=['Class 1', 'Class 2', 'Class 3', 'Class 4'], output_dict=True)\n",
        "\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "print(report_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDlgaDFRxPQE",
        "outputId": "23a44a34-fee2-4a2b-da5d-a6bed818b969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "              precision    recall  f1-score      support\n",
            "Class 1        0.587549  0.917933  0.716489   329.000000\n",
            "Class 2        0.000000  0.000000  0.000000   236.000000\n",
            "Class 3        0.698980  0.910299  0.790765   301.000000\n",
            "Class 4        0.850649  0.782869  0.815353   502.000000\n",
            "accuracy       0.708333  0.708333  0.708333     0.708333\n",
            "macro avg      0.534294  0.652775  0.580652  1368.000000\n",
            "weighted avg   0.607253  0.708333  0.645506  1368.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #6 with FastText\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, TextVectorization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "vectorizer = TextVectorization(\n",
        "    max_tokens=10000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=200\n",
        ")\n",
        "\n",
        "vectorizer.adapt(train_texts)\n",
        "\n",
        "def load_fasttext_embeddings(fasttext_file, embedding_dim=100):\n",
        "    embeddings_index = {}\n",
        "    with open(fasttext_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.rstrip().split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "fasttext_file = '/content/drive/MyDrive/Datasets/wiki-news-300d-1M.vec'\n",
        "embedding_dim = 300\n",
        "\n",
        "embeddings_index = load_fasttext_embeddings(fasttext_file, embedding_dim)\n",
        "\n",
        "embedding_matrix = np.zeros((10000, embedding_dim))\n",
        "for i in range(10000):\n",
        "    word = vectorizer.get_vocabulary()[i]\n",
        "    if word in embeddings_index:\n",
        "        embedding_matrix[i] = embeddings_index[word]\n",
        "\n",
        "model = Sequential([\n",
        "    vectorizer,\n",
        "    Embedding(input_dim=10000, output_dim=embedding_dim,\n",
        "              weights=[embedding_matrix], input_length=200, trainable=False),\n",
        "    LSTM(32),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_texts, train_labels, epochs=5, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxkuBsv7haLq",
        "outputId": "d3a65727-805c-43c8-fa10-c44571c154dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.4225 - loss: 1.2780 - val_accuracy: 0.7221 - val_loss: 0.7849\n",
            "Epoch 2/5\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.6941 - loss: 0.7727 - val_accuracy: 0.7278 - val_loss: 0.7724\n",
            "Epoch 3/5\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - accuracy: 0.6647 - loss: 0.8043 - val_accuracy: 0.5929 - val_loss: 0.9728\n",
            "Epoch 4/5\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.4793 - loss: 1.1818 - val_accuracy: 0.5649 - val_loss: 1.0088\n",
            "Epoch 5/5\n",
            "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - accuracy: 0.5906 - loss: 0.9535 - val_accuracy: 0.7000 - val_loss: 0.7521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "val_predictions = model.predict(val_texts)\n",
        "\n",
        "val_predictions = val_predictions.argmax(axis=1)\n",
        "\n",
        "val_true_labels = val_labels.argmax(axis=1)\n",
        "\n",
        "report = classification_report(val_true_labels, val_predictions, target_names=['Class 1', 'Class 2', 'Class 3', 'Class 4'], output_dict=True)\n",
        "\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "print(report_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBDzW02yhmyM",
        "outputId": "899ccc3f-e131-440c-cb8b-4d76232d80fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "              precision    recall  f1-score     support\n",
            "Class 1        0.609544  0.936667  0.738502   300.00000\n",
            "Class 2        1.000000  0.004630  0.009217   216.00000\n",
            "Class 3        0.624277  0.919149  0.743546   235.00000\n",
            "Class 4        0.836879  0.737500  0.784053   480.00000\n",
            "accuracy       0.692120  0.692120  0.692120     0.69212\n",
            "macro avg      0.767675  0.649486  0.568829  1231.00000\n",
            "weighted avg   0.769513  0.692120  0.629261  1231.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tQKgExPkuu9M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}